â„ï¸ Advanced Snowflake Features â€” Deep Practical Guide

Covers:

1ï¸âƒ£ External storage & Azure
2ï¸âƒ£ Snowpipe & incremental ingestion
3ï¸âƒ£ Integrations & governance
4ï¸âƒ£ Secure data sharing
5ï¸âƒ£ Marketplace & publishing

ğŸ”¹ 1ï¸âƒ£ SNOWFLAKE ON AZURE & EXTERNAL STORAGE
A. WORKING WITH AZURE STORAGE
âœ… What external storage options does Snowflake support?

Snowflake can integrate with:

Azure Blob Storage

Azure Data Lake Storage (ADLS Gen2)

AWS S3

Google Cloud Storage

Snowflake never hosts these files â€” it simply reads them.

âœ… What is Azure Blob Storage?

A general-purpose cloud object store used for:

raw files

logs

CSV / JSON / Parquet datasets

Blob is ideal when simple object storage is sufficient.

âœ… What is Azure Data Lake Storage (ADLS)?

ADLS Gen2 is optimized for analytics workloads, providing:

hierarchical folders

fine-grained security

scalable low-latency file access

Preferred when building data lakes.

âœ… How does Snowflake connect to Azure storage?

Connection happens through:

â¡ external stages
â¡ external tables
â¡ COPY / UNLOAD commands

Snowflake does not pull files blindly â€” it uses secure credentials.

âœ… What is external stage authentication?

The mechanism Snowflake uses to prove identity when reading/writing external files.

Two main options:

1ï¸âƒ£ SAS tokens / access keys
2ï¸âƒ£ Storage integrations (recommended)

âœ… What is a SAS token?

A temporary signed key granting access to a specific container or path.

âœ” easy
âŒ insecure if leaked
âŒ needs rotation manually

âœ… What is storage integration?

A secure trust relationship between Snowflake and Azure.

Snowflake authenticates using its cloud identity, not passwords.

Benefits:

âœ” no secrets stored in SQL
âœ” centrally controlled
âœ” auditable
âœ” rotates automatically

âœ… Why prefer storage integration over SAS keys?

Because SAS keys behave like passwords.

If exposed:

âŒ attackers can read data
âŒ access is hard to track
âŒ manual revocation required

Storage integrations eliminate that risk.

âœ… What permissions are required on storage?

Minimum required access such as:

read on blobs for ingestion

write when unloading

list for file discovery

Always follow least privilege.

âœ… What security risks exist if keys are exposed?

Someone could:

âš  copy your data externally
âš  delete files
âš  plant malicious files

This is why integrations are best practice.

B. CREATING & USING EXTERNAL STAGES
âœ… What is an external stage?

A pointer in Snowflake to cloud storage.

It does not store files â€” it stores location + credential mapping.

âœ… How is it different from an internal stage?

Internal stage lives inside Snowflake storage.

External stage lives in:

Blob

ADLS

S3

GCS

âœ… Can external stages store credentials?

Yes â€” but only via storage integrations (best) or SAS (discouraged).

âœ… How do we reference files?

Simply query using stage path.

âœ… Can Snowflake query files without loading them?

Yes â€” using external tables.

âœ… What is an external table?

A metadata wrapper that allows querying data in place without copying into Snowflake.

Best for:

data lakes

log analytics

staging exploration

âœ… What happens when files change?

New files become visible automatically.
Deleted files disappear.

âœ… How do partitions apply?

You define partitioning columns (often dates).
This improves pruning when scanning.

âœ… How do we ingest into internal tables?

Use COPY INTO â€¦ FROM stage or external table.

ğŸ”¹ 2ï¸âƒ£ SNOWPIPE & INCREMENTAL LOADS
A. SNOWPIPE BASICS
âœ… What is Snowpipe?

Snowflakeâ€™s continuous ingestion service.

As soon as a file lands â†’ Snowpipe loads it.

âœ… Difference vs Tasks?

Snowpipe = reacts to new files
Tasks = scheduled logic

âœ… What does â€œserverless ingestionâ€ mean?

Snowflake runs compute automatically â€” you do not manage warehouses.

âœ… Does Snowpipe need a warehouse?

No â€” ingestion compute is managed automatically.

âœ… How does Snowpipe auto-ingest?

Uses cloud notifications:

Azure Event Grid

AWS SNS / SQS

GCS Pub/Sub

Files trigger ingestion instantly.

âœ… Where do we monitor Snowpipe?

In UI or metadata views.

âœ… What happens when Snowpipe fails?

File is retried and errors are logged for review.

B. INCREMENTAL LOAD CONCEPTS
âœ… What is incremental loading?

Loading only new or changed data, instead of everything.

Benefits:

âœ” faster
âœ” cheaper
âœ” safer

âœ… Why not reload everything?

Full reloads:

waste compute

increase error risk

take longer as data grows

âœ… How do Streams + Tasks + Snowpipe work together?

ğŸ“¥ Snowpipe loads raw files
ğŸ” Streams track changes
âš™ Tasks process CDC and merge into target

This is the modern ingestion pattern.

âœ… How to avoid duplicates?

Use:

metadata columns

deduplication keys

MERGE logic

âœ… Why idempotency matters?

Running the same pipeline twice should not duplicate results.

C. DATA UNLOADING
âœ… What is unloading?

Exporting Snowflake data back to external storage.

Common use cases:

ML pipelines

archive

sharing with external systems

âœ… How do we secure exported files?

Encrypt + restrict external IAM access.

D. EXTERNAL DATA STAGES â€” SECURITY

Covers:

lifecycle retention

expiring keys

rotation

shared access

Key rule:

Snowflake never â€œownsâ€ the external data â€” governance remains with storage.

ğŸ”¹ 3ï¸âƒ£ SNOWFLAKE INTEGRATION
A. AZURE DATA FACTORY (ADF)

ADF orchestrates flows across systems.

Snowflake benefits:

âœ” scheduling
âœ” retries
âœ” multi-system pipelines

Use when pipelines involve more than Snowflake.

B. GOVERNANCE

Covers:

masking policies

row access policies

tags

lineage tracking

Governance ensures security, transparency, and compliance.

ğŸ”¹ 4ï¸âƒ£ SECURE DATA SHARING

Key concept:

Data is shared without copying.

Provider controls access.
Consumer queries instantly.

Reader accounts allow access without Snowflake license.

Governance remains essential.

ğŸ”¹ 5ï¸âƒ£ DATA MARKETPLACE

Snowflake Marketplace is like an â€œapp store for dataâ€.

Organizations can:

consume curated datasets

publish their own data products

No extracts, no file transfers.
ğŸ”¹ 6ï¸âƒ£ SCENARIOS â€” THINK LIKE AN ARCHITECT (DETAILED)

These scenarios train you to choose the right Snowflake feature â€” not just memorize definitions.

â­ Scenario 1 â€” Near real-time ingestion from ADLS

Problem

A team uploads files continuously to Azure Data Lake.
Business wants data visible in dashboards almost immediately.

Wrong thinking

â€œLetâ€™s schedule tasks every 15 minutes.â€

Scheduling creates delay. It also wastes compute.

Correct design

ğŸ‘‰ Use Snowpipe + External Stage

Flow:

1ï¸âƒ£ Files land in ADLS
2ï¸âƒ£ Event Grid notifies Snowflake
3ï¸âƒ£ Snowpipe ingests automatically
4ï¸âƒ£ Data is available within seconds/minutes

Why this is right

âœ” Serverless ingestion
âœ” Very low latency
âœ” No manual scheduling
âœ” Automatic retry & logging

â­ Scenario 2 â€” Multi-account secure data sharing

Problem

A large enterprise has multiple Snowflake accounts across departments.
They want access to the same dataset without copying terabytes.

Wrong thinking

â€œExport CSV and send via S3â€
This breaks security and creates duplicates.

Correct design

ğŸ‘‰ Use Secure Data Sharing

Provider publishes a database.
Consumer attaches to it instantly.

Key behavior

Data remains in provider account

No duplication

Provider controls revocation

Why this matters

âœ” Single source of truth
âœ” Governance friendly
âœ” Near zero storage overhead

â­ Scenario 3 â€” Protecting sensitive PII fields

Problem

Analysts need customer data â€” but must not see SSN, PAN, or phone numbers.

Wrong thinking

â€œCreate duplicate masked tables.â€

Leads to drift, mistakes, and cost.

Correct design

ğŸ‘‰ Apply Masking Policies + Role-based access

Snowflake masks differently depending on the role.

Examples:

Admin sees full value

Analyst sees partially masked value

External users see nulls

Benefit

âœ” One table
âœ” Dynamic masking
âœ” No extra copies

â­ Scenario 4 â€” Partner read-only access to curated data

Problem

A partner company wants to run analytics, but must NOT download or modify data.

Correct design options

Requirement	Choose
Partner only queries	âœ Reader Account
Partner already has Snowflake	âœ Secure Data Sharing
Partner needs physical copy	âœ Replication (rare)

Why reader accounts are great

No Snowflake subscription for partner

You still control compute

Security remains centralized

â­ Scenario 5 â€” Continuous CDC pipeline with minimal cost

Goal

Process only changed records â€” and avoid full reloads.

Correct design

ğŸ‘‰ Snowpipe + Streams + Tasks

Pipeline:

1ï¸âƒ£ Snowpipe ingests files
2ï¸âƒ£ Stream tracks changes
3ï¸âƒ£ Task merges into final tables

Why this works

âœ” Incremental
âœ” Exactly-once
âœ” Scales automatically

â­ Scenario 6 â€” Public dataset exposure

Goal

Share curated data publicly or monetize it.

Correct design

ğŸ‘‰ Publish on Snowflake Data Marketplace

Snowflake manages:

subscriptions

usage metering

secure access

Benefit

âœ” No file transfers
âœ” Immediate consumer onboarding
âœ” Revenue potential

ğŸ”¹ 7ï¸âƒ£ MISCONCEPTIONS â€” WITH TEACHER EXPLANATIONS

These are questions interviewers love because many people answer incorrectly.

âŒ â€œSnowpipe replaces ETL tools.â€

Reality

Snowpipe only gets data into Snowflake.

You still need:

transformations

quality checks

orchestration logic

Snowpipe = ingestion only.

âŒ â€œSnowpipe has zero latency.â€

Reality

There is still processing time:

cloud notification

ingestion queue

transformation step

Usually seconds to minutes â€” not instant.

âŒ â€œSecure sharing copies data to the consumer.â€

Reality

No data is moved.

Consumer queries virtual reference pointers.
Provider storage remains authoritative.

âŒ â€œConsumers can modify shared data.â€

Reality

They cannot:

no DML

no structural changes

They may only read â€” unless they copy it.

âŒ â€œExternal tables behave like normal tables.â€

Reality

They read files in storage on demand.

This means:

slower than internal tables

dependent on storage availability

schema-on-read behavior

Use cautiously for analytics, great for lakes.

âŒ â€œMarketplace data is always free.â€

Reality

Some datasets are free, others are subscription-based.

Charges depend on:

provider

license terms

compute used to query

âŒ â€œData sharing is same as exporting data.â€

Reality

Export creates duplicates.
Sharing avoids duplication entirely.

âŒ â€œTasks automatically detect new files like Snowpipe.â€

Reality

Tasks are time-based or dependency-based, not event-driven.

If you want auto-ingest â†’ use Snowpipe.

âŒ â€œGovernance features are optional.â€

Reality

Without masking, tagging, RBAC, and auditing:

compliance fails

access cannot be explained

risk increases dramatically

Governance is a core Snowflake design principle.

âŒ â€œIntegration always reduces cost.â€

Reality

More integrations sometimes:

add complexity

introduce latency

require governance overhead

Choose integrations deliberately.